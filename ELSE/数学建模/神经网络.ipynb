{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 34\u001b[0m\n\u001b[0;32m     32\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m# 损失函数为均方误差，优化方法为adam\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[39m# 训练模型\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(train_x, \n\u001b[0;32m     35\u001b[0m                     train_y, \n\u001b[0;32m     36\u001b[0m                     epochs\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m,              \u001b[39m# 训练迭代次数\u001b[39;00m\n\u001b[0;32m     37\u001b[0m                     batch_size\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m,           \u001b[39m# 每epoch采样的batch大小\u001b[39;00m\n\u001b[0;32m     38\u001b[0m                     validation_split\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m,   \u001b[39m# 从训练集再拆分验证集，作为早停的衡量指标\u001b[39;00m\n\u001b[0;32m     39\u001b[0m                     callbacks\u001b[39m=\u001b[39m[EarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m)],    \u001b[39m#早停法\u001b[39;00m\n\u001b[0;32m     40\u001b[0m                     verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)  \u001b[39m# 不输出过程  \u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m验证集最优结果：\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39mmin\u001b[39m(history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m]))\n\u001b[0;32m     44\u001b[0m model\u001b[39m.\u001b[39msummary()   \u001b[39m#打印模型概述信息\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_x' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import  matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow import random\n",
    "from keras import regularizers\n",
    "from keras.layers import Dense,Dropout,BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import  mean_squared_error\n",
    "\n",
    "np.random.seed(1) # 固定随机种子，使每次运行结果固定\n",
    "random.set_seed(1)\n",
    "\n",
    "\n",
    "# 创建模型结构：输入层的特征维数为13；1层k个神经元的relu隐藏层；线性的输出层；\n",
    "\n",
    "for k in [5,20,50]:  # 网格搜索超参数：神经元数k\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(BatchNormalization(input_dim=13))  # 输入层 批标准化 \n",
    "\n",
    "    model.add(Dense(k,  \n",
    "                    kernel_initializer='random_uniform',   # 均匀初始化\n",
    "                    activation='relu',                     # relu激活函数\n",
    "                    kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01),  # L1及L2 正则项\n",
    "                    use_bias=True))   # 隐藏层\n",
    "\n",
    "    model.add(Dropout(0.1)) # dropout法\n",
    "\n",
    "    model.add(Dense(1,use_bias=True))  # 输出层\n",
    "    model.compile(optimizer='adam', loss='mse') # 损失函数为均方误差，优化方法为adam\n",
    "    # 训练模型\n",
    "    history = model.fit(train_x, \n",
    "                        train_y, \n",
    "                        epochs=500,              # 训练迭代次数\n",
    "                        batch_size=50,           # 每epoch采样的batch大小\n",
    "                        validation_split=0.1,   # 从训练集再拆分验证集，作为早停的衡量指标\n",
    "                        callbacks=[EarlyStopping(monitor='val_loss', patience=20)],    #早停法\n",
    "                        verbose=False)  # 不输出过程  \n",
    "\n",
    "    \n",
    "    print(\"验证集最优结果：\",min(history.history['val_loss']))\n",
    "    model.summary()   #打印模型概述信息\n",
    "    # 模型评估：拟合效果\n",
    "    plt.plot(history.history['loss'],c='blue')    # 蓝色线训练集损失\n",
    "    plt.plot(history.history['val_loss'],c='red') # 红色线验证集损失\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2081893555.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[5], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    history = model.fit(train_x,\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
